{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Behaviour Cloning CNN",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "ng9XdtpoDwLK"
      },
      "source": [
        "import copy\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "from PIL import Image"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7lvuJxPfo6VM"
      },
      "source": [
        "data = torchvision.datasets.CIFAR10('~/data', train=True, download=True)\n",
        "mu = data.data.mean(axis=(0, 1, 2)) # (N, H, W, 3) -> 3\n",
        "std = data.data.std(axis=(0, 1, 2)) # (N, H, W, 3) -> 3\n",
        "print(data.data.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6OjGhxO7fhrZ"
      },
      "source": [
        "n_valid = 2000\n",
        "def Cifar10(train, trforms=None):\n",
        "  tfms_norm = torchvision.transforms.Compose([\n",
        "      transforms.ToTensor(),\n",
        "      # ToTensor already maps 0-255 to 0-1, so devide mu and std by 255 below \n",
        "      transforms.Normalize(mu / 255, std /255), \n",
        "  ])\n",
        "  tf = transforms.Compose([trforms, tfms_norm]) if trforms is not None else tfms_norm \n",
        "  return torchvision.datasets.CIFAR10(root='~/data',train=train, download=True, transform=tf)\n",
        "\n",
        "# data_train, data_valid = torch.utils.data.random_split(data_train, (45000, 5000))\n",
        "loader_kwargs = {'batch_size': 128, 'num_workers': 4}\n",
        "\n",
        "# last 5000 training images for validation\n",
        "data_valid = Cifar10(train=True)\n",
        "data_valid.data = data_valid.data[-n_valid:]\n",
        "data_valid.targets = data_valid.targets[-n_valid:]\n",
        "loader_valid = torch.utils.data.DataLoader(data_valid, **loader_kwargs)\n",
        "\n",
        "# all images in the test set\n",
        "data_test = Cifar10(train=False)\n",
        "loader_test = torch.utils.data.DataLoader(data_test, **loader_kwargs)\n",
        "\n",
        "\n",
        "def get_loader_train(augmentations=lambda x: x):\n",
        "    # first 45000 training images for training\n",
        "    data_train = Cifar10(train=True, trforms=transforms.Compose([augmentations]))\n",
        "    data_train.data = data_train.data[:-n_valid]\n",
        "    data_train.targets = data_train.targets[:-n_valid]\n",
        "    loader_train = torch.utils.data.DataLoader(data_train, **loader_kwargs, shuffle=True)\n",
        "    return loader_train"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a1hP51tKFyEw"
      },
      "source": [
        "def one_epoch(model, data_loader, opt=None):\n",
        "    device = next(model.parameters()).device\n",
        "    train = False if opt is None else True\n",
        "    model.train() if train else model.eval()\n",
        "    losses, correct, total = [], 0, 0\n",
        "    for x, y in data_loader:\n",
        "        x, y = x.to(device), y.to(device)\n",
        "        with torch.set_grad_enabled(train):\n",
        "            logits = model(x)\n",
        "        loss = F.cross_entropy(logits, y)\n",
        "\n",
        "        if train:\n",
        "            opt.zero_grad()\n",
        "            loss.backward()\n",
        "            opt.step()\n",
        "\n",
        "        losses.append(loss.item())\n",
        "        total += len(x)\n",
        "        correct += (torch.argmax(logits, dim=1) == y).sum().item()\n",
        "    return np.mean(losses), correct / total\n",
        "\n",
        "\n",
        "def train(model, loader_train, loader_valid, lr=1e-3, max_epochs=30, weight_decay=0., patience=3):\n",
        "    train_losses, train_accuracies = [], []\n",
        "    valid_losses, valid_accuracies = [], []\n",
        "\n",
        "    opt = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
        "    best_valid_accuracy = 0\n",
        "    best_valid_accuracy_epoch = 0\n",
        "\n",
        "    t = tqdm(range(max_epochs))\n",
        "    for epoch in t:\n",
        "        train_loss, train_acc = one_epoch(model, loader_train, opt)\n",
        "        train_losses.append(train_loss)\n",
        "        train_accuracies.append(train_acc)\n",
        "\n",
        "        valid_loss, valid_acc = one_epoch(model, loader_valid)\n",
        "        valid_losses.append(valid_loss)\n",
        "        valid_accuracies.append(valid_acc)\n",
        "\n",
        "        t.set_description(f'train_acc: {train_acc:.2f}, valid_acc: {valid_acc:.2f}')\n",
        "\n",
        "        if valid_acc > best_valid_accuracy:\n",
        "            best_valid_accuracy = valid_acc\n",
        "            best_valid_accuracy_epoch = epoch\n",
        "\n",
        "        if epoch > best_valid_accuracy_epoch + patience:\n",
        "            break\n",
        "    t.set_description(f'best valid acc: {best_valid_accuracy:.2f}')\n",
        "\n",
        "    return train_losses, train_accuracies, valid_losses, valid_accuracies\n",
        "\n",
        "\n",
        "def plot_history(train_losses, train_accuracies, valid_losses, valid_accuracies):\n",
        "    plt.figure(figsize=(7, 3))\n",
        "\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.xlabel('epoch')\n",
        "    plt.ylabel('loss')\n",
        "    p = plt.plot(train_losses, label='train')\n",
        "    plt.plot(valid_losses, label='valid')\n",
        "    plt.ylim(0, 2)\n",
        "    plt.legend()\n",
        "    plt.grid()\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.xlabel('epoch')\n",
        "    plt.ylabel('accuracy')\n",
        "    p = plt.plot(train_accuracies, label='train')\n",
        "    plt.plot(valid_accuracies, label='valid')\n",
        "    plt.ylim(0, 1.05)\n",
        "    plt.legend()\n",
        "    plt.grid()\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eD0fe3vbxBrM"
      },
      "source": [
        "model = torchvision.models.resnet18(pretrained=True)\n",
        "#print(model)\n",
        "# See that the head after the conv-layers (in the bottom) is one linear layer, from 512 features to 1k-class logits.\n",
        "# We want to replace it with a new head to 10-class logits:\n",
        "model.fc = nn.Linear(512, 10)\n",
        "# Also, the model has been trained on images with a resolution of 224. Let's upscale our cifar10 images:\n",
        "\n",
        "model = nn.Sequential(\n",
        "    nn.UpsamplingBilinear2d((224,224)),\n",
        "    model,\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ujCpOUaxxlFp"
      },
      "source": [
        "model = model.cuda()\n",
        "loader_train = get_loader_train(affine_hflip)\n",
        "plot_history(*train(model,loader_train,loader_valid, lr=1e-4))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gk-L1HQcyGIa"
      },
      "source": [
        "test_acc = one_epoch(model, loader_test)[1]\n",
        "print(f'{test_acc * 100:.1f} % test accuracy')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
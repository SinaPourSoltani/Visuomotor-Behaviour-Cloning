{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Behaviour Cloning CNN",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "venv",
      "display_name": "venv",
      "language": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "f33b265c025f452988bcd28ab109957b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_0928fd6e1e7e4ed1aa850ee9c16856b1",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_2a3f2de4c5ab49b8bd6e0be3741f3ee2",
              "IPY_MODEL_7353602918a54950984e2a400a184fd9"
            ]
          }
        },
        "0928fd6e1e7e4ed1aa850ee9c16856b1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2a3f2de4c5ab49b8bd6e0be3741f3ee2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_1222f3d83852420297e6307f96395da3",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 46827520,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 46827520,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d9b15935e36d4ae8874a7b767aefe2c7"
          }
        },
        "7353602918a54950984e2a400a184fd9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_5e691de697f84ce281557c1973089fbd",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 44.7M/44.7M [00:00&lt;00:00, 95.9MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ebde3803f62c49a3b958b28460ad7cce"
          }
        },
        "1222f3d83852420297e6307f96395da3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d9b15935e36d4ae8874a7b767aefe2c7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5e691de697f84ce281557c1973089fbd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ebde3803f62c49a3b958b28460ad7cce": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "iBfoFQYeP8t6",
        "outputId": "223f13f0-78e3-485a-9053-e8dca098af0a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!git clone https://github.com/SinaPourSoltani/Visuomotor-Behaviour-Cloning.git\n",
        "!pip3 install -r \"Visuomotor-Behaviour-Cloning/requirements.txt\"\n",
        "\n",
        "import os \n",
        "os.kill(os.getpid(), 9)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'Visuomotor-Behaviour-Cloning'...\n",
            "remote: Enumerating objects: 848, done.\u001b[K\n",
            "remote: Counting objects: 100% (848/848), done.\u001b[K\n",
            "remote: Compressing objects: 100% (545/545), done.\u001b[K\n",
            "remote: Total 848 (delta 463), reused 672 (delta 297), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (848/848), 6.80 MiB | 21.04 MiB/s, done.\n",
            "Resolving deltas: 100% (463/463), done.\n",
            "Collecting pybullet\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/73/6d/60b97ffc579db665bdd87f2cb47fe1215ae770fbbc1add84ebf36ddca63b/pybullet-3.1.7.tar.gz (79.0MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 79.0MB 123kB/s \n",
            "\u001b[?25hCollecting numpy>=1.20.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a5/42/560d269f604d3e186a57c21a363e77e199358d054884e61b73e405dd217c/numpy-1.20.3-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (15.3MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15.3MB 364kB/s \n",
            "\u001b[?25hRequirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from -r Visuomotor-Behaviour-Cloning/requirements.txt (line 3)) (7.1.2)\n",
            "Collecting dataclasses\n",
            "  Downloading https://files.pythonhosted.org/packages/26/2f/1095cdc2868052dd1e64520f7c0d5c8c550ad297e944e641dbf1ffbb9a5d/dataclasses-0.6-py3-none-any.whl\n",
            "Collecting attrdict\n",
            "  Downloading https://files.pythonhosted.org/packages/ef/97/28fe7e68bc7adfce67d4339756e85e9fcf3c6fd7f0c0781695352b70472c/attrdict-2.0.1-py2.py3-none-any.whl\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from -r Visuomotor-Behaviour-Cloning/requirements.txt (line 6)) (1.1.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from -r Visuomotor-Behaviour-Cloning/requirements.txt (line 7)) (4.41.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from -r Visuomotor-Behaviour-Cloning/requirements.txt (line 8)) (1.8.1+cu101)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from -r Visuomotor-Behaviour-Cloning/requirements.txt (line 9)) (0.9.1+cu101)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from -r Visuomotor-Behaviour-Cloning/requirements.txt (line 10)) (3.2.2)\n",
            "Collecting numpy-quaternion\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8b/e4/bf6fab7c2559da41fa96d22acf2a70e5378fc2df96bdd2146b484cf6cace/numpy_quaternion-2021.4.5.14.42.35-cp37-cp37m-manylinux2010_x86_64.whl (188kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 194kB 54.9MB/s \n",
            "\u001b[?25hCollecting datetime\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/73/22/a5297f3a1f92468cc737f8ce7ba6e5f245fcfafeae810ba37bd1039ea01c/DateTime-4.3-py2.py3-none-any.whl (60kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61kB 8.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from attrdict->-r Visuomotor-Behaviour-Cloning/requirements.txt (line 5)) (1.15.0)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->-r Visuomotor-Behaviour-Cloning/requirements.txt (line 6)) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->-r Visuomotor-Behaviour-Cloning/requirements.txt (line 6)) (2.8.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->-r Visuomotor-Behaviour-Cloning/requirements.txt (line 8)) (3.7.4.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->-r Visuomotor-Behaviour-Cloning/requirements.txt (line 10)) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->-r Visuomotor-Behaviour-Cloning/requirements.txt (line 10)) (1.3.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->-r Visuomotor-Behaviour-Cloning/requirements.txt (line 10)) (2.4.7)\n",
            "Collecting zope.interface\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bb/a7/94e1a92c71436f934cdd2102826fa041c83dcb7d21dd0f1fb1a57f6e0620/zope.interface-5.4.0-cp37-cp37m-manylinux2010_x86_64.whl (251kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 256kB 46.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from zope.interface->datetime->-r Visuomotor-Behaviour-Cloning/requirements.txt (line 12)) (56.1.0)\n",
            "Building wheels for collected packages: pybullet\n",
            "  Building wheel for pybullet (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pybullet: filename=pybullet-3.1.7-cp37-cp37m-linux_x86_64.whl size=89750969 sha256=3411dda016d2dc45ab3eb315e75d7cd0292dc7584198abff489f9060673c8ab0\n",
            "  Stored in directory: /root/.cache/pip/wheels/30/56/e6/fce8276a2f30165f7ac31089bb72f390fa16b87328651e1a5a\n",
            "Successfully built pybullet\n",
            "\u001b[31mERROR: tensorflow 2.4.1 has requirement numpy~=1.19.2, but you'll have numpy 1.20.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Installing collected packages: pybullet, numpy, dataclasses, attrdict, numpy-quaternion, zope.interface, datetime\n",
            "  Found existing installation: numpy 1.19.5\n",
            "    Uninstalling numpy-1.19.5:\n",
            "      Successfully uninstalled numpy-1.19.5\n",
            "Successfully installed attrdict-2.0.1 dataclasses-0.6 datetime-4.3 numpy-1.20.3 numpy-quaternion-2021.4.5.14.42.35 pybullet-3.1.7 zope.interface-5.4.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nyOjHvLDhp3P"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UJgMGBKWN1Ii",
        "outputId": "d5eb3d42-797a-4537-e89d-205f0f481979",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 767,
          "referenced_widgets": [
            "f33b265c025f452988bcd28ab109957b",
            "0928fd6e1e7e4ed1aa850ee9c16856b1",
            "2a3f2de4c5ab49b8bd6e0be3741f3ee2",
            "7353602918a54950984e2a400a184fd9",
            "1222f3d83852420297e6307f96395da3",
            "d9b15935e36d4ae8874a7b767aefe2c7",
            "5e691de697f84ce281557c1973089fbd",
            "ebde3803f62c49a3b958b28460ad7cce"
          ]
        }
      },
      "source": [
        "import sys\n",
        "import json\n",
        "from datetime import datetime\n",
        "from torchvision import transforms\n",
        "sys.path.append('Visuomotor-Behaviour-Cloning')\n",
        "from BehaviourCloningCNN import *\n",
        "\n",
        "std_noise_poke_vec=None\n",
        "is_stereo = False\n",
        "complex_mlp = False\n",
        "p_dropout = 0.0\n",
        "normalise_poke = False\n",
        "\n",
        "\n",
        "#augmentations = transforms.Compose([\n",
        "#    transforms.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1, hue=0.1),\n",
        "#    transforms.GaussianBlur(kernel_size=5),\n",
        "#    transforms.RandomAffine(degrees=2,translate=(0.02,0.02),interpolation=transforms.functional.InterpolationMode.BILINEAR, fill=(255,255,255)),\n",
        "#])\n",
        "augmentations = None\n",
        "\n",
        "# Without shadows\n",
        "#data_link = \"https://github.com/SinaPourSoltani/Visuomotor-Behaviour-Cloning/releases/download/v0.2/data.zip\"\n",
        "#is_stereo = False\n",
        "\n",
        "# With Shadows\n",
        "data_link = \"https://github.com/SinaPourSoltani/Visuomotor-Behaviour-Cloning/releases/download/v0.3/data.zip\"\n",
        "is_stereo = False\n",
        "\n",
        "# Stereo Images\n",
        "#data_link = \"https://github.com/SinaPourSoltani/Visuomotor-Behaviour-Cloning/releases/download/v0.4/data.zip\" \n",
        "#complex_mlp = False\n",
        "\n",
        "\n",
        "\n",
        "load_data(data_link)\n",
        "train_loader, valid_loader, test_loader = get_data_loaders(*get_episodes(),transforms=augmentations, is_stereo=is_stereo, std_noise_poke_vec=std_noise_poke_vec)\n",
        "model = get_model(normalise_poke_vec=normalise_poke, complex_mlp=complex_mlp, is_stereo=is_stereo, p_dropout=p_dropout)\n",
        "\n",
        "train_loss =  []\n",
        "test_loss = []"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Headers:            ['image_file_name', 'âˆ†x', 'âˆ†y', 'âˆ†z', 'episode']\n",
            "Number of episodes: 501\n",
            "Number of images:   52938\n",
            "Images per episode: [152  79  72 123 171 149 106  89  69 137 105 128  66 112  78  52 139  98\n",
            "  71 162  79 141 130 108 137 128  93  89  90 152  67 124 125 103 128  80\n",
            " 116  57 173 125 135  65  86 112 116 106  84 133 143  79  54  72  89  57\n",
            " 104  90  78 145  62  76 165  87 119  95  75  98 118 126  51  80  81 187\n",
            "  90  88 127 117  71 163  72 112  99  74 112  98  86  76  74 103  86 104\n",
            " 191  49  67 200 130  67  79 141 109 118  63  47 165 109  71  60  89  86\n",
            " 109 193 184  98  98  65 135 130 117 125 105 123  54 140  48  93 135  95\n",
            " 133 124  74 104  51  94  94  53 108 114 107  80 148  95  60 124  53 125\n",
            "  76 136 126 148 105 153  74  94  82  94  79 170  87  89  55  83 136 147\n",
            " 124 119 123 181 121  63 169 138 115  68 144  73 145  80 131  73  91 193\n",
            "  83  55 130  90 145 175  67  82 124  89 157 119 106 103  58 130  76 175\n",
            " 111 124 127 140 123 125  57  89  64  61  81  97  62 183 129 221  90 141\n",
            " 134  87 136 129  94 125  97  70  92 106  96 173  57 116 128 123 114  92\n",
            " 114 130  67 213  69 100  94  76  71  76  86 128 128  89 127 125 113 128\n",
            " 130 129 115 123 142 134  75  63  87  96 108 103 114  92  74 129  80 101\n",
            "  86  96  84 132 148 149 100 121  86  74  76  72 128  94  55 104  50  79\n",
            "  84  80  99 128  97 107 159  82 162 164  92  92  58 112  83  56 115 115\n",
            " 188  84  83  93  87 105  56  88  69 113  69 130 120  91 142 101 111  96\n",
            "  82 104 138  59  82  99  81 122  63  66  42  78 116  62 107  57  64  71\n",
            "  93  68 113 102  59  58 157  78  85  92 169 109 161 133  88 123 105 120\n",
            " 128  86  77 110 107 129 155  73 157  79 133  92 175 100 176 105 101  76\n",
            " 120 150 213 109 142  76  53 111  52  71 115 157 119 123 143  78  99  96\n",
            " 104 142 197 108 139 126 123 109 105 155 113 126  70  79 124 159  62 102\n",
            "  94 162 118 105 102  86 105 133 122 119 131 101 171 182  65 106 104 132\n",
            "  58  61  93  71  75  89 104  59 109  86  69  75 106 118 126  89 128 135\n",
            "  72  99 149 148 155  56  51  89 154 102  86 159 104  67  78  89 103 133\n",
            " 176 122 134  73 104 105  89  76  90  66  97  90  55 120 166 119  90  70\n",
            "  93 145 101 100  73 143  80  59 129  61  54  68 204  69 130]\n",
            "Episodes:\n",
            "Train: 350 | ~0.70\n",
            "Valid: 100 | ~0.20\n",
            "Test : 51 | ~0.10\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet18-5c106cde.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-5c106cde.pth\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f33b265c025f452988bcd28ab109957b",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=46827520.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "In here cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r5EDRrwDM8Cu",
        "outputId": "497c50fd-e10b-4cfe-cc8e-b6df4bbb9334",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!cd Visuomotor-Behaviour-Cloning && git pull"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "remote: Enumerating objects: 5, done.\u001b[K\n",
            "remote: Counting objects:  20% (1/5)\u001b[K\rremote: Counting objects:  40% (2/5)\u001b[K\rremote: Counting objects:  60% (3/5)\u001b[K\rremote: Counting objects:  80% (4/5)\u001b[K\rremote: Counting objects: 100% (5/5)\u001b[K\rremote: Counting objects: 100% (5/5), done.\u001b[K\n",
            "remote: Compressing objects: 100% (1/1)\u001b[K\rremote: Compressing objects: 100% (1/1), done.\u001b[K\n",
            "remote: Total 3 (delta 2), reused 3 (delta 2), pack-reused 0\u001b[K\n",
            "Unpacking objects:  33% (1/3)   \rUnpacking objects:  66% (2/3)   \rUnpacking objects: 100% (3/3)   \rUnpacking objects: 100% (3/3), done.\n",
            "From https://github.com/SinaPourSoltani/Visuomotor-Behaviour-Cloning\n",
            "   8c2f71e..b529768  main       -> origin/main\n",
            "Updating 8c2f71e..b529768\n",
            "Fast-forward\n",
            " BehaviourCloningCNN.py | 4 \u001b[32m++\u001b[m\u001b[31m--\u001b[m\n",
            " 1 file changed, 2 insertions(+), 2 deletions(-)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KCLOEz6xNtLq",
        "outputId": "e7db92bb-bd6c-4fb3-92ab-52724cee2392",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model = freeze_backbone(model, is_stereo=is_stereo)\n",
        "train_loss, tmp_train_acc, test_loss, tmp_test_acc = train(model,train_loader,valid_loader, lr=1e-4, max_epochs=15, patience=-1, is_stereo=is_stereo, model_tag=\"baseline_2.0\")\n",
        "plot_history(train_loss, tmp_train_acc, test_loss, tmp_test_acc)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train_loss: 0.0870028395, valid_loss: 0.0648924734:   7%|â–‹         | 1/15 [02:33<35:42, 153.01s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "train_loss: 0.0446994384, valid_loss: 0.0601575497:  13%|â–ˆâ–Ž        | 2/15 [05:08<33:20, 153.88s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "train_loss: 0.0316533500, valid_loss: 0.0572881268:  20%|â–ˆâ–ˆ        | 3/15 [07:45<30:57, 154.77s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xk9yyByaN7Fs",
        "outputId": "39fbf36d-225b-49b3-f401-bf41fd818595",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 694
        }
      },
      "source": [
        "model.load_state_dict(torch.load(\"ResNet18_epoch5_baseline_rm_norm.pth\"))\n",
        "model = unfreeze_backbone(model, is_stereo=is_stereo)\n",
        "tmp_train_loss, tmp_train_acc, tmp_test_loss, tmp_test_acc = train(model,train_loader,valid_loader, lr=1e-5, max_epochs=15, patience=15, is_stereo=is_stereo, model_tag=\"baseline_rm_norm_unfrozen2\")\n",
        "\n",
        "# save loss for later use\n",
        "train_loss += tmp_train_loss\n",
        "test_loss += tmp_test_loss\n",
        "\n",
        "plot_history(tmp_train_loss, tmp_train_acc, tmp_test_loss, tmp_test_acc)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "  0%|          | 0/15 [00:00<?, ?it/s]\u001b[A\n",
            "train_loss: 0.0106903892, valid_loss: 0.0365800211:   0%|          | 0/15 [02:29<?, ?it/s]\u001b[A\n",
            "train_loss: 0.0106903892, valid_loss: 0.0365800211:   7%|â–‹         | 1/15 [02:29<34:56, 149.76s/it]\u001b[A\n",
            "train_loss: 0.0070828463, valid_loss: 0.0364390936:   7%|â–‹         | 1/15 [05:00<34:56, 149.76s/it]\u001b[A\n",
            "train_loss: 0.0070828463, valid_loss: 0.0364390936:  13%|â–ˆâ–Ž        | 2/15 [05:00<32:29, 149.95s/it]\u001b[A\n",
            "train_loss: 0.0054822787, valid_loss: 0.0373414905:  13%|â–ˆâ–Ž        | 2/15 [07:30<32:29, 149.95s/it]\u001b[A\n",
            "train_loss: 0.0054822787, valid_loss: 0.0373414905:  20%|â–ˆâ–ˆ        | 3/15 [07:30<29:59, 149.99s/it]\u001b[A\n",
            "train_loss: 0.0045207979, valid_loss: 0.0374842094:  20%|â–ˆâ–ˆ        | 3/15 [09:56<29:59, 149.99s/it]\u001b[A\n",
            "train_loss: 0.0045207979, valid_loss: 0.0374842094:  27%|â–ˆâ–ˆâ–‹       | 4/15 [09:56<27:18, 148.95s/it]\u001b[A\n",
            "train_loss: 0.0039744137, valid_loss: 0.0366269655:  27%|â–ˆâ–ˆâ–‹       | 4/15 [12:24<27:18, 148.95s/it]\u001b[A\n",
            "train_loss: 0.0039744137, valid_loss: 0.0366269655:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 5/15 [12:24<24:45, 148.55s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-15d37df68f9b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ResNet18_epoch5_baseline_rm_norm.pth\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munfreeze_backbone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_stereo\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mis_stereo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtmp_train_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtmp_train_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtmp_test_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtmp_test_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalid_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatience\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_stereo\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mis_stereo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_tag\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"baseline_rm_norm_unfrozen2\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# save loss for later use\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/Visuomotor-Behaviour-Cloning/BehaviourCloningCNN.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, loader_train, loader_valid, lr, max_epochs, weight_decay, patience, is_stereo, model_tag)\u001b[0m\n\u001b[1;32m    208\u001b[0m     \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 210\u001b[0;31m         \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mone_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloader_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_stereo\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mis_stereo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    211\u001b[0m         \u001b[0mtrain_losses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m         \u001b[0mtrain_accuracies\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_acc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/Visuomotor-Behaviour-Cloning/BehaviourCloningCNN.py\u001b[0m in \u001b[0;36mone_epoch\u001b[0;34m(model, data_loader, opt, is_stereo)\u001b[0m\n\u001b[1;32m    191\u001b[0m         \u001b[0mtotal\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_stereo\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mvector_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvector_gt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 193\u001b[0;31m           \u001b[0mtotal_deviation\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mgeo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mangle_between_vectors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvector_pred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvector_gt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    194\u001b[0m         \u001b[0;31m#correct += correct_poke(y.cpu().detach().numpy(), logits.cpu().detach().numpy()) #(torch.argmax(logits, dim=1) == y).sum().item()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_deviation\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mtotal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/Visuomotor-Behaviour-Cloning/utilities.py\u001b[0m in \u001b[0;36mangle_between_vectors\u001b[0;34m(v1, v2)\u001b[0m\n\u001b[1;32m    133\u001b[0m             \u001b[0mnorm_prod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 135\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marccos\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mnorm_prod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mamax\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36mamax\u001b[0;34m(a, axis, out, keepdims, initial, where)\u001b[0m\n\u001b[1;32m   2732\u001b[0m     \"\"\"\n\u001b[1;32m   2733\u001b[0m     return _wrapreduction(a, np.maximum, 'max', axis, None, out,\n\u001b[0;32m-> 2734\u001b[0;31m                           keepdims=keepdims, initial=initial, where=where)\n\u001b[0m\u001b[1;32m   2735\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2736\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36m_wrapreduction\u001b[0;34m(obj, ufunc, method, axis, dtype, out, **kwargs)\u001b[0m\n\u001b[1;32m     85\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpasskwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mufunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpasskwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RFe9U4s2hp3U"
      },
      "source": [
        "time_stamp = datetime.now().strftime(\"%d-%H-%M\")\n",
        "filename = \"ResNet18_\" + time_stamp + \".pth\"\n",
        "torch.save(model.state_dict(), filename)\n",
        "\n",
        "summary = {}\n",
        "summary[\"Model name\"] = filename; \n",
        "summary[\"Epochs\"] = len(train_loss)\n",
        "summary[\"Train loss\"] = train_loss\n",
        "summary[\"Test loss\"] = test_loss\n",
        "summary[\"Is stereo\"] = is_stereo\n",
        "summary[\"Complex_mlp\"] = complex_mlp\n",
        "summary[\"p_dropout\"] = p_dropout\n",
        "summary[\"std_noise_poke_vec\"] = std_noise_poke_vec\n",
        "summary[\"augmentations\"] = augmentations\n",
        "summary[\"Normalise_poke_vector\"] = normalise_poke\n",
        "\n",
        "summary_file_name = \"summary_\" + time_stamp\n",
        "with open(summary_file_name, 'w') as outfile:\n",
        "            json.dump(summary, outfile)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-wKPrdyWhp3V"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}